{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pT5oTLwrPth"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import emcee\n",
        "from scipy.stats import beta\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test an estimation on real data**"
      ],
      "metadata": {
        "id": "v2oRqTOUrYvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "file_path = '/Users/echo/Downloads/df_germany.csv'  # Update this path to where your file is located\n",
        "df = pd.read_csv(file_path)\n",
        "df = df[df[\"brand\"]==\"absolut\"]\n",
        "\n",
        "# Define the dependent variable\n",
        "Y_t = df['volume_so_off'].values\n",
        "\n",
        "\n",
        "# df['brand'] = df['brand'].astype('category').cat.codes\n",
        "\n",
        "# Define the independent variables for X_t and Z_t\n",
        "# Adjust these columns based on actual needs\n",
        "X_t = df[['relative_gap_to_90th_price_off_off', 'off_trade_visibility_off', 'digital_off', 'digital_social_media_off',\"out_of_home_off\",\n",
        "          'television_off', 'brand_experience_off']].values\n",
        "Z_t = df[['distribution_off_off', 'discount_price_comp_to_pr_off_off']].values"
      ],
      "metadata": {
        "id": "teEi6zE3rYFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preliminary experiments**"
      ],
      "metadata": {
        "id": "OIsGlv_XtHtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Here we need an initial guess and use a naive estimation of the parameters**"
      ],
      "metadata": {
        "id": "GkLfwUTItABi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimation_eta_zeta(X_t,Z_t,Y_t):\n",
        "  XZ_t = np.hstack((X_t, Z_t))\n",
        "  # Fit the linear regression model\n",
        "  model_XZ = LinearRegression().fit(XZ_t, Y_t_normalized)\n",
        "  eta_zeta = model_XZ.coef_\n",
        "  # Separate eta and zeta\n",
        "  eta = eta_zeta[:X_t.shape[1]]\n",
        "  zeta = eta_zeta[X_t.shape[1]:]\n",
        "  return([eta,zeta])"
      ],
      "metadata": {
        "id": "g3hBdzNOs_QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second experiments"
      ],
      "metadata": {
        "id": "tDAkCFJdtUi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Initial parameter values\n",
        "# initial_params = [0.5] + [0.0] * (X_t.shape[1] + Z_t.shape[1])\n",
        "# Original parameters\n",
        "original_G = 0.7\n",
        "original_eta = eta\n",
        "original_zeta = zeta\n",
        "\n",
        "# Add Gaussian noise to the initial parameters\n",
        "initial_G = original_G + np.random.normal(0, 0.01)\n",
        "initial_eta = original_eta + np.random.normal(0, 0.01, size=original_eta.shape)\n",
        "initial_zeta = original_zeta + np.random.normal(0, 0.01, size=original_zeta.shape)\n",
        "\n",
        "# Combine the initial parameters\n",
        "initial_params = [initial_G] + list(initial_eta) + list(initial_zeta)\n",
        "\n",
        "# Perform gradient descent\n",
        "optimized_params = gradient_descent(Y_t, X_t, Z_t, initial_params)\n",
        "\n",
        "# Extract optimized parameters\n",
        "G, *coeffs = optimized_params\n",
        "\n",
        "eta = np.array(coeffs[:X_t.shape[1]])\n",
        "zeta = np.array(coeffs[X_t.shape[1]:])\n",
        "\n",
        "print(\"new G\", G)\n",
        "print(\"new eta\", eta)\n",
        "print(\"new zeta\", zeta)\n",
        "\n",
        "# Define the DLM function according to the formula\n",
        "def dlm_model_optimized(X_t, Z_t, eta, zeta, G, T):\n",
        "    theta_t = np.zeros(T)\n",
        "    predicted_Y = np.zeros(T)\n",
        "    for t in range(T):\n",
        "        if t > 0:\n",
        "            theta_t[t] = G * theta_t[t-1] + np.dot(Z_t[t-1], zeta / 2)\n",
        "        predicted_Y[t] = theta_t[t] + np.dot(X_t[t], eta) + np.dot(Z_t[t], zeta / 2)\n",
        "\n",
        "    return predicted_Y\n",
        "\n",
        "# Define the number of time steps\n",
        "T = len(Y_t)\n",
        "\n",
        "# Predict Y_t using the optimized DLM model\n",
        "optimized_predicted_Y = dlm_model_optimized(X_t, Z_t, eta, zeta, G, T)\n",
        "\n",
        "# Convert the results to a DataFrame for visualization\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual_Y': scaler_Y.inverse_transform(Y_t.reshape(-1, 1)).flatten(),\n",
        "    'Optimized_Predicted_Y': scaler_Y.inverse_transform(optimized_predicted_Y.reshape(-1, 1)).flatten()\n",
        "})\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "# Evaluate the model performance\n",
        "mse = mean_squared_error(results_df['Actual_Y'], results_df['Optimized_Predicted_Y'])\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(results_df['Actual_Y'], label='Actual Y_t')\n",
        "plt.plot(results_df['Optimized_Predicted_Y'], label='Optimized Predicted Y_t', linestyle='--')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Volume Sold')\n",
        "plt.title('Actual vs Optimized Predicted Y_t')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vFZ3yfm9tWPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third experiments"
      ],
      "metadata": {
        "id": "xQ6c8B2stnQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for i...:\n",
        "# y_t[i]=dlm_model(X_t, Z_t, eta, zeta, G, T)\n",
        "#param[i]=estimation_gradient_descent(Y_t, X_t, Z_t, initial_params, learning_rate=0.001, n_iterations=500)"
      ],
      "metadata": {
        "id": "vfVncF6_tsT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}